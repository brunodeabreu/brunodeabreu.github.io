[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bruno de Abreu Machado",
    "section": "",
    "text": "Eu sou Bruno, trabalho com suporte ao banco de dados Db2 UDB na Kyndryl, sou de Belo Horizonte/MG."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "Predicting Visitor Purchases with BigQuery ML\n\n\n\n\n\n\n\nGCP\n\n\nPMLE\n\n\nBigQuery\n\n\n\n\nThis Lab from Google PMLE course where I practice BigQuery ML\n\n\n\n\n\n\nSep 29, 2023\n\n\nBruno Machado\n\n\n\n\n\n\n  \n\n\n\n\nStep by step to create a first computer vision model\n\n\n\n\n\n\n\nfastai\n\n\npytorch\n\n\nCNN\n\n\n\n\nThis tutorial describe how to create a computer vision model to classify if the picture is from real Michael Jackson or a look alike person\n\n\n\n\n\n\nSep 18, 2023\n\n\nBruno Machado\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-09-30-first-post/index.html",
    "href": "posts/2022-09-30-first-post/index.html",
    "title": "Step by step to create a first computer vision model",
    "section": "",
    "text": "Kaggle notebook Application\n\n\nOn kaggle creare a notebook : File/New notebook\n\n\n\n\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\n\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\n\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\n\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\n\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\n\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\n\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\n\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\n\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\n\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\n\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "posts/2022-09-30-first-post/index.html#i.-why-blog",
    "href": "posts/2022-09-30-first-post/index.html#i.-why-blog",
    "title": "Why create presentation slides about blogging when you can just blog about it instead?",
    "section": "I. Why blog?",
    "text": "I. Why blog?\nData science blogging has become pretty darn popular in recent years, and for good reason. It can help you to build your online professional profile, enhance your communication skills, stay atop the latest and greatest trends and tools, connect with other data scientists, and even solicit feedback from those in the community.\nBut arguably one of the most valuable reasons to blog is to get a whole lot better at doing whatever it is you want to write about. You’ve probably heard some version of the saying, “The best way to learn something is to teach it to others” – not only do I find this to be true of myself, but there’s also science1 to back this up!\nStill, getting started can be a bit intimidating (I’m only doing this for the first time now myself). It an attempt to make it a little less so for the next blogger-to-be, I have tried to gather some ideas, instructions, and inspiration to get things going. If nothing else, I think heeding the advice of this tweet2 is a pretty good place to start:"
  },
  {
    "objectID": "notas.html",
    "href": "notas.html",
    "title": "Cursos & Treinamentos",
    "section": "",
    "text": "Professional Machine Learning Engineer\n\n\n\ngcp\n\n\nmachine learning\n\n\ngoogle\n\n\n\nGoogle path professional Machine Learning Engineer\n\n\n\nBruno\n\n\nSep 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAWS Machine Learning – Specialty\n\n\n\ndatacamp\n\n\npython\n\n\ndata science\n\n\n\nAWS Machine Learning – Specialty\n\n\n\nBruno\n\n\nSep 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science with Python - DataCamp\n\n\n\ndatacamp\n\n\npython\n\n\ndata science\n\n\n\nData Science with python Carrer path\n\n\n\nBruno\n\n\nSep 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep learning for Coders fast.ai\n\n\n\nDL\n\n\npython\n\n\nfastai\n\n\n\nA hands-on coding course from fast.ai\n\n\n\nBruno\n\n\nSep 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#experiência",
    "href": "index.html#experiência",
    "title": "Bruno de Abreu Machado",
    "section": "experiência",
    "text": "experiência\n\n DBA Db2\nAdministrador de banco de dados Db2 para plataformas Linux, Unix e Windows - IBM / Kyndryl"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "meu hobby\nEu e minha esposa temos um hobby que contruimos em comum de viajar, separar um momento para recarregar as energias.\n;)\n minha distração\n correr"
  },
  {
    "objectID": "notas/2022-02-18-intro-to-linux/index.html",
    "href": "notas/2022-02-18-intro-to-linux/index.html",
    "title": "Intro to Linux",
    "section": "",
    "text": "test\n\nTEst"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "On Windows we can install PowerShell and WSL using, the first time you\nwsl --install\n\nTips :\n\nTerminal Full Screen : &lt;Alt+Enter&gt;\nSwitch between users : sudo -u &lt;user&gt; -i\nCheck version and python location : which python\nInstall everything in homedir to do not mix the system python/files with our version of python used to DEV and experiment\n\n\n\n\nTo install tmux sudo apt install tmux\n\nhttps://tmuxcheatsheet.com/\nCtrl + b + % : Divide terminal in the middle vertical\nCtrl + b + \" : Divide terminal in the middle horizontal\nCtrl + b + direction : Move between terminals\nCtrl + b + z : zoom in or zoom out a spefic terminal\nCtrl + d : close\n\n\n\n\n\n\n\nGithub for conda mini-forge and mamba-forge installer conda-forge/miniforge\nLinux Manbaforge install\n\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\n\nInstall Mambaforge, this going to install several libsn\n\n  bash Mambaforge-Linux-x86_64.sh \n\nThe command which python should show right now /home/bruno/mambaforge/bin/python\n\n\n\n\n\n\n\nTo setup fastai in our notebook Github-Fastsetup\n\nRun the wget to donwload the setupconda.sh and install\n\nwget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh\n\nbash setup-conda.sh\n\n\n\n\n\n\nConda and Mamba is two ways of doing the same thing, however today mamba is very fast\n\nInstall ipython : mamba install ipython\nPytorch install : pytorch get-started\n\nCPU : mamba install pytorch torchvision torchaudio cpuonly -c pytorch\nCUDA : mamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\nTest : ipython -&gt; import torch\n\nInstall Jupyter Lab : mamba install jupyterlab\n\nCreate a alias to jupyter lab –no-browser : alias jl=jupyter lab --no-browser\n\nInstall ipywidgets : mamba install ipywidgets\n\n\n\n\nGit repository is a folder that contain files and sub-folders that we can store and git keeps a copy of every version of files\n\n\nThe below figure describe how to create a new repo we can :\n\nMake the repo private or public\nAdd a readme file\nConfigure .gitignore\nChoose a license\n\ns ::: {.callout-important} DO NOT share password or keys on github :::\n\n\n\nSTEPS :\n\nOn terminal create a public key ssh-keygen, it will create public (id_rsa.pub) and private (id_rsa) keys\nIn github.com/settings/ssh/ click in New SSH Key and add the content of id_rsa.pub\nNow you will be able to clone the .git repository and save your changes\n\n\n\n\nThe complete list of git commands\n\nCommit : git commit -m &lt;message&gt;\nPush : git push\nPull : git pull\nadd : git add &lt;file&gt;\nremove : git rm &lt;file&gt;\nstatus : git status\n\n\n\n\n\nTo start the jupyter notebook we can issue : jupyter lab --no-browser\nTip :\n\ncreate an alias like alias jl=jupyter lab --no-browser and just issue jl to start the jupyter lab\nJupyter Docs\n\n\n\n\nSTEPS:\n\nGo to fastbook on github and click on Fork to create your copy of the book\nClone your version of book : git clone git@github.com:brunodeabreu/fastbook.git\nInstall fastai : mamba install -c fastchan fastai\n\ndocs.fast.ai\n\nInstall fastbook : mamba install -c fastchan fastbok or pip instal -Uqq fastbook\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we install fastbook it also install fastai\n\n\n\n\n\nSTEPS :\n\nCreate : mamba create -n tmp 'python&lt;3.10' fastcore\nActivate: mamba activate  tmp\nDeactivate: mamba deactivate tmp\n\n\n\n\n\n\n\nNote\n\n\n\nTo return to (base) we can only issue conda activate\n\n\n\n\n\nUsing https://www.paperspace.com/artificial-intelligence we can get a FREE GPU server.\nWe can signup with github or gmail account and select gradient it will request you to create a project and after that you can create notebooks/servers.\n\n\n\nSTEPS :\n\nOpen colab.research.google.com, you can sigup with your google account\nGo to Ferramentas -&gt; Configurações -&gt; Gihub -&gt; Autorizar com Github\nArquivo -&gt; Abrir notebook -&gt; Select your fastbook repository, if you do not have your own copy fork from fastai/fastbook\n\n\n\n\nConfig Gihub Repo on Colab\n\n\n\nSelect the notebook and open in a new tab\nChange the enviroment to TPU : Go to Ambiente de execução -&gt; Alterar tipo de ambiente de exeção -&gt; Select T4 GPU\n\n\n\n\nOpen the course.fast.ai on Colab session click on each chapter."
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#setup-conda-install",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#setup-conda-install",
    "title": "#1 Deep learning for Coders fast.ai - Prep-Work",
    "section": "3.1 Setup conda install",
    "text": "3.1 Setup conda install\nTo setup fastai in our notebook Github-Fastsetup\n\nRun the wget to donwload the setupconda.sh and install\n\nwget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh\n\nbash setup-conda.sh"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#create-new-repo",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#create-new-repo",
    "title": "#1 Deep learning for Coders fast.ai - Prep-Work",
    "section": "5.1 Create new repo",
    "text": "5.1 Create new repo\nThe below figure describe how to create a new repo we can :\n\nMake the repo private or public\nAdd a readme file\nConfigure .gitignore\nChoose a license\n\ns ::: {.callout-important} DO NOT share password or keys on github :::"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#section",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#section",
    "title": "Deep learning for Coders fast.ai - Prep-Work",
    "section": "5.2",
    "text": "5.2"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#configure-ssh-key-o-github",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#configure-ssh-key-o-github",
    "title": "Deep learning for Coders fast.ai - Prep-Work",
    "section": "5.2 Configure SSH Key o Github",
    "text": "5.2 Configure SSH Key o Github\nSTEPS :\n\nOn terminal create a public key ssh-keygen, it will create public (id_rsa.pub) and private key (id_rsa)\nIn github.com/settings/ssh/ click in New SSH Key and add the content of id_rsa.pub"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#configure-ssh-key-o-github-and-clone-.git-repository",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#configure-ssh-key-o-github-and-clone-.git-repository",
    "title": "#1 Deep learning for Coders fast.ai - Prep-Work",
    "section": "5.2 Configure SSH Key o Github and clone .git repository",
    "text": "5.2 Configure SSH Key o Github and clone .git repository\nSTEPS :\n\nOn terminal create a public key ssh-keygen, it will create public (id_rsa.pub) and private (id_rsa) keys\nIn github.com/settings/ssh/ click in New SSH Key and add the content of id_rsa.pub\nNow you will be able to clone the .git repository and save your changes"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#commit-push-pull-status",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#commit-push-pull-status",
    "title": "#1 Deep learning for Coders fast.ai - Prep-Work",
    "section": "5.3 Commit, push, pull, status",
    "text": "5.3 Commit, push, pull, status\nThe complete list of git commands\n\nCommit : git commit -m &lt;message&gt;\nPush : git push\nPull : git pull\nadd : git add &lt;file&gt;\nremove : git rm &lt;file&gt;\nstatus : git status"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#tmux",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#tmux",
    "title": "#1 Deep learning for Coders fast.ai - Prep-Work",
    "section": "",
    "text": "To install tmux sudo apt install tmux\n\nhttps://tmuxcheatsheet.com/\nCtrl + b + % : Divide terminal in the middle vertical\nCtrl + b + \" : Divide terminal in the middle horizontal\nCtrl + b + direction : Move between terminals\nCtrl + b + z : zoom in or zoom out a spefic terminal\nCtrl + d : close"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#basic-cmds-commit-push-pull-status",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#basic-cmds-commit-push-pull-status",
    "title": "#1 Deep learning for Coders fast.ai - Prep-Work",
    "section": "5.3 Basic Cmds : Commit, push, pull, status",
    "text": "5.3 Basic Cmds : Commit, push, pull, status\nThe complete list of git commands\n\nCommit : git commit -m &lt;message&gt;\nPush : git push\nPull : git pull\nadd : git add &lt;file&gt;\nremove : git rm &lt;file&gt;\nstatus : git status"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html",
    "href": "notas/2023-09-06-intro-deep-learning/index.html",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Kaggle notebook\n\n\nOn kaggle creare a notebook : File/New notebook\n\n\n\n\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\n\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\n\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\n\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\n\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\n\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\n\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\n\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\n\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\n\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\n\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-1",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-1",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "On kaggle creare a notebook : File/New notebook"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-2",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-2",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Install fast ai\n!pip install -Uqq fastai"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-3",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-3",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Import fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-4",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-4",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Create a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-5",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-5",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Try use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nEMU\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nEMA\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-6",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-6",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Lets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-8",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-8",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Remove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-9",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-9",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Create a data loader\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-10",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-10",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Lets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#is-michael-jackson-alive",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#is-michael-jackson-alive",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Kaggle notebook\n\n\nOn kaggle creare a notebook : File/New notebook"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-2-install-fastai",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-2-install-fastai",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Install fast ai\n!pip install -Uqq fastai"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-3-import-libs",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-3-import-libs",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Import fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-4-create-search-function",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-4-create-search-function",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Create a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-5-test-the-search-function",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-5-test-the-search-function",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Try use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-6-download-images",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-6-download-images",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Lets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-8-clean-failed-images",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-8-clean-failed-images",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Remove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-9-create-data-block",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-9-create-data-block",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Create a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-10-train-the-model",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-10-train-the-model",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Lets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-11-export-and-download-the-model",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-11-export-and-download-the-model",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "learn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-2-install-packages",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-2-install-packages",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Install fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-11-test-the-model",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-11-test-the-model",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "is_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-12-create-spaces-on-huggingface.co",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-12-create-spaces-on-huggingface.co",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Access [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-13-create-the-app",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-13-create-the-app",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Clone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-12-export-and-download-the-model",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-12-export-and-download-the-model",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "learn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-13-create-spaces-on-huggingface.co",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-13-create-spaces-on-huggingface.co",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Access [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-14-create-the-app",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-14-create-the-app",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "Clone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo"
  },
  {
    "objectID": "notas/2023-09-06-intro-deep-learning/index.html#step-15-test-the-app",
    "href": "notas/2023-09-06-intro-deep-learning/index.html#step-15-test-the-app",
    "title": "#2 Deep learning for Coders fast.ai - Cap 01",
    "section": "",
    "text": "If the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#terminal",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#terminal",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "On Windows we can install PowerShell and WSL using, the first time you\nwsl --install\n\nTips :\n\nTerminal Full Screen : &lt;Alt+Enter&gt;\nSwitch between users : sudo -u &lt;user&gt; -i\nCheck version and python location : which python\nInstall everything in homedir to do not mix the system python/files with our version of python used to DEV and experiment\n\n\n\n\nTo install tmux sudo apt install tmux\n\nhttps://tmuxcheatsheet.com/\nCtrl + b + % : Divide terminal in the middle vertical\nCtrl + b + \" : Divide terminal in the middle horizontal\nCtrl + b + direction : Move between terminals\nCtrl + b + z : zoom in or zoom out a spefic terminal\nCtrl + d : close"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#install-python",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#install-python",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "Github for conda mini-forge and mamba-forge installer conda-forge/miniforge\nLinux Manbaforge install\n\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\n\nInstall Mambaforge, this going to install several libsn\n\n  bash Mambaforge-Linux-x86_64.sh \n\nThe command which python should show right now /home/bruno/mambaforge/bin/python"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#setup-fastai",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#setup-fastai",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "To setup fastai in our notebook Github-Fastsetup\n\nRun the wget to donwload the setupconda.sh and install\n\nwget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh\n\nbash setup-conda.sh"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#install-other-packages-using-mamba",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#install-other-packages-using-mamba",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "Conda and Mamba is two ways of doing the same thing, however today mamba is very fast\n\nInstall ipython : mamba install ipython\nPytorch install : pytorch get-started\n\nCPU : mamba install pytorch torchvision torchaudio cpuonly -c pytorch\nCUDA : mamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\nTest : ipython -&gt; import torch\n\nInstall Jupyter Lab : mamba install jupyterlab\n\nCreate a alias to jupyter lab –no-browser : alias jl=jupyter lab --no-browser\n\nInstall ipywidgets : mamba install ipywidgets"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#git",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#git",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "Git repository is a folder that contain files and sub-folders that we can store and git keeps a copy of every version of files\n\n\nThe below figure describe how to create a new repo we can :\n\nMake the repo private or public\nAdd a readme file\nConfigure .gitignore\nChoose a license\n\ns ::: {.callout-important} DO NOT share password or keys on github :::\n\n\n\nSTEPS :\n\nOn terminal create a public key ssh-keygen, it will create public (id_rsa.pub) and private (id_rsa) keys\nIn github.com/settings/ssh/ click in New SSH Key and add the content of id_rsa.pub\nNow you will be able to clone the .git repository and save your changes\n\n\n\n\nThe complete list of git commands\n\nCommit : git commit -m &lt;message&gt;\nPush : git push\nPull : git pull\nadd : git add &lt;file&gt;\nremove : git rm &lt;file&gt;\nstatus : git status"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#jupyter-lab",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#jupyter-lab",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "To start the jupyter notebook we can issue : jupyter lab --no-browser\nTip :\n\ncreate an alias like alias jl=jupyter lab --no-browser and just issue jl to start the jupyter lab\nJupyter Docs"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#clone-the-fastai-book-and-install-fastai",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#clone-the-fastai-book-and-install-fastai",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "STEPS:\n\nGo to fastbook on github and click on Fork to create your copy of the book\nClone your version of book : git clone git@github.com:brunodeabreu/fastbook.git\nInstall fastai : mamba install -c fastchan fastai\n\ndocs.fast.ai\n\nInstall fastbook : mamba install -c fastchan fastbok or pip instal -Uqq fastbook\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we install fastbook it also install fastai"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#create-an-enviroment",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#create-an-enviroment",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "STEPS :\n\nCreate : mamba create -n tmp 'python&lt;3.10' fastcore\nActivate: mamba activate  tmp\nDeactivate: mamba deactivate tmp\n\n\n\n\n\n\n\nNote\n\n\n\nTo return to (base) we can only issue conda activate"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#creating-paperspace-notebook",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#creating-paperspace-notebook",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "Using https://www.paperspace.com/artificial-intelligence we can get a FREE GPU server.\nWe can signup with github or gmail account and select gradient it will request you to create a project and after that you can create notebooks/servers."
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#google-colab",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#google-colab",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "STEPS :\n\nOpen colab.research.google.com, you can sigup with your google account\nGo to Ferramentas -&gt; Configurações -&gt; Gihub -&gt; Autorizar com Github\nArquivo -&gt; Abrir notebook -&gt; Select your fastbook repository, if you do not have your own copy fork from fastai/fastbook\n\n\n\n\nConfig Gihub Repo on Colab\n\n\n\nSelect the notebook and open in a new tab\nChange the enviroment to TPU : Go to Ambiente de execução -&gt; Alterar tipo de ambiente de exeção -&gt; Select T4 GPU"
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#best-option-to-access-the-book-and-notebooks",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#best-option-to-access-the-book-and-notebooks",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "Open the course.fast.ai on Colab session click on each chapter."
  },
  {
    "objectID": "notas/2023-09-01-pre-work-deep-learning/index.html#step-by-step-to-create-the-first-model",
    "href": "notas/2023-09-01-pre-work-deep-learning/index.html#step-by-step-to-create-the-first-model",
    "title": "Deep learning for Coders fast.ai",
    "section": "Step by step to create the first model",
    "text": "Step by step to create the first model\n\nIs Michael Jackson alive ?\nKaggle notebook\n\nSTEP 1 : Create notebook on kaggle\nOn kaggle creare a notebook : File/New notebook\n\n\n\nSTEP 2: install packages\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\nSTEP 3: import libs\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\nSTEP 4: create search function\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\nSTEP 5: Test the search function\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\nSTEP 6 : Download images\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\nSTEP 8: clean failed images\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\nSTEP 9: Create data block\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\nSTEP 10: Train the model\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\nSTEP 11: Test the model\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\nSTEP 12: Export and Download the model\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\nSTEP 13 : Create spaces on huggingFace.co\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\nSTEP 14: Create the app\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\nSTEP 15: Test the APP\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html",
    "href": "notas/2023-09-01-deep-learning/index.html",
    "title": "Deep learning for Coders fast.ai",
    "section": "",
    "text": "The idea of fine tune NLP model started with ULMFIT, which is first presented in a fast.ai course\nThe ULMFIT process using RNN:\n\nBuild a language model using wikipedia text (Wikitext 103) , this model try to predict the next word of Wikipedia article.\nAdd more epochs using IMDb movies review, now our model are good to predict next word of IMDb reviews\nFine tune tune to predict whether or not a movie review was positive or negative sentiment\n\nTokenization :\n\nThe Huggingface transformers use the Dataset object to tokenize the text\nTransform the pandas dataframe into huggingface dataset\n\nfrom datasets import Dataset.DatasetDict\n\nds = Dataset.from_pandas(df)\n\nA deep learning model expects numbers as inputs, so we need:\n\nTokenization : Split each text up into words(or actually, as we’ll see, into tokens)\nNumericalization: Convert each word (or token) into a number (unique ID)\n\nBefore we start to tokenizer we need to decide what model to use, for instance access Hugging Face - Models and search on model hub.\nAutoTokenizer will create a tokenizer appropriae for a given model\nmodel_nm = 'microsoft/debert-v3-small'\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\ntokz = AutoTokenizer.from_pretrained(model_mn)\n\n\n\nIn time series instead of remove data from the middle it is better to truncate the last weeks\nFastai will show the metrics from validation dataset\nHow (and why) to create a good validation set"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#terminal",
    "href": "notas/2023-09-01-deep-learning/index.html#terminal",
    "title": "Deep learning for Coders fast.ai",
    "section": "1. Terminal",
    "text": "1. Terminal\nOn Windows we can install PowerShell and WSL using, the first time you\nwsl --install\n\nTips :\n\nTerminal Full Screen : &lt;Alt+Enter&gt;\nSwitch between users : sudo -u &lt;user&gt; -i\nCheck version and python location : which python\nInstall everything in homedir to do not mix the system python/files with our version of python used to DEV and experiment\n\n\n\n1.1 tmux\nTo install tmux sudo apt install tmux\n\nhttps://tmuxcheatsheet.com/\nCtrl + b + % : Divide terminal in the middle vertical\nCtrl + b + \" : Divide terminal in the middle horizontal\nCtrl + b + direction : Move between terminals\nCtrl + b + z : zoom in or zoom out a spefic terminal\nCtrl + d : close"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#install-python",
    "href": "notas/2023-09-01-deep-learning/index.html#install-python",
    "title": "Deep learning for Coders fast.ai",
    "section": "2. Install python",
    "text": "2. Install python\n\nGithub for conda mini-forge and mamba-forge installer conda-forge/miniforge\nLinux Manbaforge install\n\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\n\nInstall Mambaforge, this going to install several libsn\n\n  bash Mambaforge-Linux-x86_64.sh \n\nThe command which python should show right now /home/bruno/mambaforge/bin/python"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#setup-fastai",
    "href": "notas/2023-09-01-deep-learning/index.html#setup-fastai",
    "title": "Deep learning for Coders fast.ai",
    "section": "3. Setup fastai",
    "text": "3. Setup fastai\n\n3.1 Setup conda install\nTo setup fastai in our notebook Github-Fastsetup\n\nRun the wget to donwload the setupconda.sh and install\n\nwget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh\n\nbash setup-conda.sh"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#install-other-packages-using-mamba",
    "href": "notas/2023-09-01-deep-learning/index.html#install-other-packages-using-mamba",
    "title": "Deep learning for Coders fast.ai",
    "section": "4. Install other packages using mamba",
    "text": "4. Install other packages using mamba\nConda and Mamba is two ways of doing the same thing, however today mamba is very fast\n\nInstall ipython : mamba install ipython\nPytorch install : pytorch get-started\n\nCPU : mamba install pytorch torchvision torchaudio cpuonly -c pytorch\nCUDA : mamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\nTest : ipython -&gt; import torch\n\nInstall Jupyter Lab : mamba install jupyterlab\n\nCreate a alias to jupyter lab –no-browser : alias jl=jupyter lab --no-browser\n\nInstall ipywidgets : mamba install ipywidgets"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#git",
    "href": "notas/2023-09-01-deep-learning/index.html#git",
    "title": "Deep learning for Coders fast.ai",
    "section": "5. Git",
    "text": "5. Git\nGit repository is a folder that contain files and sub-folders that we can store and git keeps a copy of every version of files\n\n5.1 Create new repo\nThe below figure describe how to create a new repo we can :\n\nMake the repo private or public\nAdd a readme file\nConfigure .gitignore\nChoose a license\n\ns ::: {.callout-important} DO NOT share password or keys on github :::\n\n\n5.2 Configure SSH Key o Github and clone .git repository\nSTEPS :\n\nOn terminal create a public key ssh-keygen, it will create public (id_rsa.pub) and private (id_rsa) keys\nIn github.com/settings/ssh/ click in New SSH Key and add the content of id_rsa.pub\nNow you will be able to clone the .git repository and save your changes\n\n\n\n5.3 Basic Cmds : Commit, push, pull, status\nThe complete list of git commands\n\nCommit : git commit -m &lt;message&gt;\nPush : git push\nPull : git pull\nadd : git add &lt;file&gt;\nremove : git rm &lt;file&gt;\nstatus : git status"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#jupyter-lab",
    "href": "notas/2023-09-01-deep-learning/index.html#jupyter-lab",
    "title": "Deep learning for Coders fast.ai",
    "section": "6. Jupyter lab",
    "text": "6. Jupyter lab\nTo start the jupyter notebook we can issue : jupyter lab --no-browser\nTip :\n\ncreate an alias like alias jl=jupyter lab --no-browser and just issue jl to start the jupyter lab\nJupyter Docs"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#clone-the-fastai-book-and-install-fastai",
    "href": "notas/2023-09-01-deep-learning/index.html#clone-the-fastai-book-and-install-fastai",
    "title": "Deep learning for Coders fast.ai",
    "section": "7. Clone the Fastai book and install fastai",
    "text": "7. Clone the Fastai book and install fastai\nSTEPS:\n\nGo to fastbook on github and click on Fork to create your copy of the book\nClone your version of book : git clone git@github.com:brunodeabreu/fastbook.git\nInstall fastai : mamba install -c fastchan fastai\n\ndocs.fast.ai\n\nInstall fastbook : mamba install -c fastchan fastbok or pip instal -Uqq fastbook\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we install fastbook it also install fastai"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#create-an-enviroment",
    "href": "notas/2023-09-01-deep-learning/index.html#create-an-enviroment",
    "title": "Deep learning for Coders fast.ai",
    "section": "8. Create an enviroment",
    "text": "8. Create an enviroment\nSTEPS :\n\nCreate : mamba create -n tmp 'python&lt;3.10' fastcore\nActivate: mamba activate  tmp\nDeactivate: mamba deactivate tmp\n\n\n\n\n\n\n\nNote\n\n\n\nTo return to (base) we can only issue conda activate"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#creating-paperspace-notebook",
    "href": "notas/2023-09-01-deep-learning/index.html#creating-paperspace-notebook",
    "title": "Deep learning for Coders fast.ai",
    "section": "9. Creating paperspace notebook",
    "text": "9. Creating paperspace notebook\nUsing https://www.paperspace.com/artificial-intelligence we can get a FREE GPU server.\nWe can signup with github or gmail account and select gradient it will request you to create a project and after that you can create notebooks/servers."
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#google-colab",
    "href": "notas/2023-09-01-deep-learning/index.html#google-colab",
    "title": "Deep learning for Coders fast.ai",
    "section": "10. Google Colab",
    "text": "10. Google Colab\nSTEPS :\n\nOpen colab.research.google.com, you can sigup with your google account\nGo to Ferramentas -&gt; Configurações -&gt; Gihub -&gt; Autorizar com Github\nArquivo -&gt; Abrir notebook -&gt; Select your fastbook repository, if you do not have your own copy fork from fastai/fastbook\n\n\n\n\nConfig Gihub Repo on Colab\n\n\n\nSelect the notebook and open in a new tab\nChange the enviroment to TPU : Go to Ambiente de execução -&gt; Alterar tipo de ambiente de exeção -&gt; Select T4 GPU"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#best-option-to-access-the-book-and-notebooks",
    "href": "notas/2023-09-01-deep-learning/index.html#best-option-to-access-the-book-and-notebooks",
    "title": "Deep learning for Coders fast.ai",
    "section": "11. Best option to access the book and notebooks",
    "text": "11. Best option to access the book and notebooks\nOpen the course.fast.ai on Colab session click on each chapter."
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#step-by-step-to-create-the-first-model",
    "href": "notas/2023-09-01-deep-learning/index.html#step-by-step-to-create-the-first-model",
    "title": "Deep learning for Coders fast.ai",
    "section": "Step by step to create the first model",
    "text": "Step by step to create the first model\n\nIs Michael Jackson alive ?\nKaggle notebook\n\nSTEP 1 : Create notebook on kaggle\nOn kaggle creare a notebook : File/New notebook\n\n\n\nSTEP 2: install packages\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\nSTEP 3: import libs\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\nSTEP 4: create search function\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\nSTEP 5: Test the search function\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\nSTEP 6 : Download images\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\nSTEP 8: clean failed images\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\nSTEP 9: Create data block\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\nSTEP 10: Train the model\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\nSTEP 11: Test the model\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\nSTEP 12: Export and Download the model\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\nSTEP 13 : Create spaces on huggingFace.co\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\nSTEP 14: Create the app\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\nSTEP 15: Test the APP\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#notes-from-video-1",
    "href": "notas/2023-09-01-deep-learning/index.html#notes-from-video-1",
    "title": "Deep learning for Coders fast.ai",
    "section": "Notes from video 1",
    "text": "Notes from video 1\nMotivation :\n\nHow to build a compyter vision classifier ?\n\n\nA pixel is recognized by RGB number, that going to be an input to computer vision model\nTo train a colection of image we need a DataBlock, this provides to fastai all the information it needs to create a Computer Vision model\nWhen we create the model using visual_learner it going to learn from each image that you input\nTo predict and check we call .predict it will return a probability\n\nHow the model learn ?\n\nEach layer will learn small things, like diagonal, circle ….\n\nFastai Lib\n\nBuilded on top of pyTorch\nWe can use colab, gradient, sagemaker, kaggle to develop\nSamples simple computer vision classifier:\n\nIs it a bird ?\nIs Michael Jackson Alive ?\n\n\nDataBlock\n\nHow do I get “this data” into my model ?\n\nWe create a DataBlock and according the structure and options fastai will know the type of model to create, we need to inform:\n\nWhat kind of input do we have ? ImageBlock\nWhat kind of output ? CategoryBlock\nProvide a list of ALL image files and path get_image_files\nReserve some data to validate RandomSplitter\nHow do we know the correct label of photo parent_label\nTransform the image Resize\n\nThis will create a DataBlock using a pyTorch function dataloaders, this is what pyTorch interate to get bunch of data\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\nTo read more https://docs.fast.ai/tutorial.datablock.html\nOn the end we will have a dls (dataloaders) object that contains iterators where pyTorch can run through to grab batches of random data (training and validation ) images\nWhat is a Learner ?\nThis is a critical concept in fastai. the learner is something which combines a model (the Neural Network function) and the data we use to train\nLearner = NN fuction + data\nTo create a learner we pass :\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\ndata (dls)\nmodel resnet18 , this is the neural network function\n\nWhat is resnet18? Someone trained this model to recognize over a million of images of over 1000 different types from ImageNet dataset and create those weights\n\nMetrics\n\n\n\n\n\n\n\ntimm\n\n\n\nFastai integrate with Pytorch Images models (timm) a collection of computer vision models, layers, utilities, optimizers, etc…\n\n\nTo complete the train, fastai have a method fine_tune that takes those pre-trained weights and adjusts to teach the model the differences between our dataset and ImageNet dataset or any other.\nTo use the model/learn, predict\nCall .predict passing an image and it return the probability(prob).\n\nIt is not only computer vision we can work with :\n\n\nTo create a Segmentation we can use\n\nSegmentationDataLoaders\nunet_learner as a learner\n\nTabular analysis\n\nImport lib : from fastai.tabular.all import *\nTabularDataLoader.from_csv to create the dataloader\ntabular_learner to create the learner\nlearn.fit_one_cycle(2) to fit the model\n\nCollaborative filtering (recommendation system)\n\nImport lib from fastai.collab import *\nCollabDataLoader.from_csv Create the dataloader\nThe learner collab_learner and fine_tune or fit_one_cycle\n\nNLP, etc…"
  },
  {
    "objectID": "posts/2022-09-30-first-post/index.html#step-by-step-to-create-the-first-model",
    "href": "posts/2022-09-30-first-post/index.html#step-by-step-to-create-the-first-model",
    "title": "Step by step to create a first computer vision model",
    "section": "",
    "text": "Kaggle notebook Application\n\n\nOn kaggle creare a notebook : File/New notebook\n\n\n\n\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\n\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\n\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\n\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\n\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\n\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\n\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\n\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\n\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\n\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\n\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "Professional Machine Learning Engineer"
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#introduction-to-ai-and-machine-learning",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#introduction-to-ai-and-machine-learning",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "This course provide a toolbox which is full of AI tecnologies and tools offered by Google\n\nFoundation : cloud essentials\nDevelopement : different options to build ML and Workflow\nSolutions :Vertical and horizontal solutions and generative AI\n\n\n\n\n\nGoogle is a leader in developement of AI and it offers a wide range of tools\nand provides :\n\nState-of-the-art ML models\nEnd-to-end model development and MLOps - Productivity\nUnified data to AI plataform\nEfficient and scalable AI - Infrastructure\n\n7 principals AI should be:\n\nsocially beneficial\nAvoid creating or reinforcing unfair bias\nBuild and tested for safety\nAccountable to people\nIncorporate privancy design principles\nUphold high standards of scientific excelence\nMade available for uses that accord with these principles\n\n\n\n\n\nComputer Engine : IaaS with compute , storage, network similar to a phisical machine\nGoogle Kubernetes Engine : Containerized applications\nApp Engine : PaaS, binds code to libraries and developed can be focused on appl logic\nCloud Functions : Executes code in response to events. Functions as a services\nCloud Run : Fully managed platform, auto scales up and down, charge only by resources you use\n\n\n\n\nCPU : Central processing unit\nGPU : Graphics processing unit\nTPU : Tensor Processing Unit\n\n\n\n\n\n\n\nTPU\n\n\n\nTPU are faster and more energy-efficient for AI and ML applications.\nThis is the state-of-the-art hardware and supercomputing technology is available with Google Cloud products and services\n\n\n\n\n\n\nHow to choose from these products and services ?\n\nIt depends of data type and bussiness needs\nUnstructured data\n\nCloud Storage\n\nStandard storage - Hot data\nNearline storage - Once per month\nColdline storage - Once every 90 days\nArchive storage - Once a year\n\n\nStructure data\n\nTransactional\n\nSQL\n\nlocal/reginal : Cloud SQL\nglobal : Cloud spanner\n\nNoSQL : Firestore\n\nAnalytical\n\nSQL : BigQuery\nNOSQL : Cloud Bigtable\n\n\n\n\n\n\nProducts available in each stage of the data-to-AI workflow\n\nIngestion and processing : (Pub/Sub, Dataflow, Dataproc and Cloud Data Fusion)\nStorage : (CloudSQL, Cloud Spanner, Cloud BigTable and Firestore)\nAnalytics : (BigQuery and looker)\nAI/ML : (VertexAI)\n\n\n\n\nAI includes anything related to computer mimicking human intelligence (Robts and self-driving cars)\nMachine Learning is a subset of AI that allows computers to learn without being explicity programmed\n\n\n\n\nWith BigQuery ML, you can manage the tabular data and execute ML models in one place with just a few steps\nKey phases of Machine Learning project\n\nExtract, transform, and load data into BigQuery\nSelect and preprocess featres\n\n\nBigQuery ML does some preprocessing for us, like one-hot encoding\n\n\nCreate the model\n\n#standarSQL\n\nCREATE MODEL\necommerce.classification\n\nOPTIONS\n(\n  model_type='logistic_reg'\n  input_label_cols='will_buy_later'\n\n) AS \n\n# SQL with training data\n\nThere are others algorithms :\n\n\n\nBigQuery Model Selection\n\n\n\nEvaluate the performance of the trained model\n\nSELECT \n  roc_auc,\n  accuracy,\n  precision,\n  recall\nFROM \n  ML.EVALUATE(MODEL`ecommerce.classification`)\n\nUse the model to make predictions\n\nSELECT * FROM\n  ML.PREDICT\n  (\n    MODEL.`ecommerce.classification` )\n\n\n\n\n\nGoogle offers to build a machine learning models\n\nPre-trained APIs : Use ML models that google already built and trained\nBigQuery ML : Use SQL queries to create and execute ML models in BigQuery\nAutoML : Apply no-code solution to build ml models on Vertex AI\nCustom training : Code your own ML env to have the control over the ML pipeline\n\n\n\nAPI (Application Programming Interface) define how software components communicate with each other.\n\nCloud Natural Language API : recognizes parts of speech called entities and sentiment.\nCloud Speech-to-Text : convert audio to text\nCloud Translation API : convert text from one language to another\nCloud Vision : recognizes content in static images\nCloud Video Intelligence : recognizes motion and actions in a video\nDiagflow API : builds conversational interfaces\nGenerative AI related APIs :\n\nPaLM for text : perform language tasks and tune the LLM model with your own data.\nPaLM for chat : create applications that engage users in dynamic and context-aware conversations.\nImage for image : create and edit images\nEmbeddings API for text and Image : extract semantic information from unstructured data.\nChirp for speech : build voice\nCody for code generation : produce and debug code\n\nNatural Language API\n\nTry - demo\n\n\n\n\n\nVertex AI provides an end-to-end ML, pipeline to prepare data, and create, deploy, and manage models over time, and at scale.\nWe can think of Vertex AI Workbench as a Jupyter notebook deployed in a single development environment\n\n\n\nAutomate the process to develop and deploy an ML model.\nAutoML automates the pipeline from feature ngineering, to architecture search, to hyperparameter tuning, and to model ensembly\n\n\n\nDo-it-yourself solution to build an ML project.\nWhich environment you want your ML training code to use.\n\npre-built container\ncustom container\n\nCan use ML Library (TensorFlow, scikit-learn, and PyTorch.) collection of pre-written code that can be used to perform machine learning tasks.\nTensorFlow\n\n\n\n\n\n\n\n\n\nThere are several types of Neural Networks that solves different problems\n\nANN artificial neural network\nDNN deep neural network\nCNN convolutional neural network\nRNN recurrent neural network\nLLM large language models\n\nSTEP 1 : calculate the weighted sum multiplying each input value by its corresponding weight, and then summing the products\n\nSTEP 2: apply an activation function to the weighted sum.\n\nSTEP 3 : the weighted sum is calculated for the output layer\nSTEP 4 : apply an activation function to the weighted sum\n\nSTEP 5 : calculate the cost function to minimize the difference.\n\nCost functions for : * regression (MSE) * classfication (Cross-entropy)\nSTEP 6: backpropagation\nif the difference between the predicted and actual results is significant, you must go back to adjust weights and biases to minimize the cost function.\n\nSTEP 7: Interate the process (epoch)\n\n\nwe can set the number of epochs as a hyperparameter in training\nwe can tell that the cost function has reached its optimum when the value stops decreasing, even after many iterations.\n\n\nThis is how a neural network learns : It iterates the learning by continuously adjusting weights to improve behavior until it reaches the best result.\n\n\n\n\nactivation function is used to prevent linearity or add non-linearity.\n\n\nReLU\nSigmoid : binary classfication\nSoftmax : multi-class classification\nTanH\netc …\n\n\n\n\n\nStages :\n\nData preparation (Upload data and Feature engineer)\nModel development\nModel serving\n\n\n\n\nDuring this stage, you must upload data and then prepare it for model training with feature engineering.\n\nfeature engineering: the data must be processed before the model starts training.\nVertex AI provides a function called Vertex AI Feature Store, which is a centralized repository to organize, store, and serve features.\n\n\n\n\nAfter data is ready it is time to training the model, this stage involves two iterative steps :\n\nModel training\nModel evaluation\n\nVertex AI provides extensive evaluation metrics to help determine a model’s performance. A confusion matrix is a specific performance measurement for machine learning classification problems.\n\nRecall : refers to all the positive cases, and looks at how many were predicted correctly. Precision : refers to all the cases predicted as positive, and how many are actually positive.\n\n\n\n\nOn this stage we have two steps :\n\nDeploy model\nMonitor the model\n\nThere are 3 options to deploy a model\n\nEndpoint\nBatch prediction\nOffline prediction\n\nTo monitor there are a toolkit Vertex AI Pipelines\n\n\n\n\nMLOps means automating and monitoring each step of the ML system construction to enable continuous integration, training, and delivery.\n\n\nMLOps on Vertex AI is a tool kit called Vertex AI Pipelines that supports :\n\nKubeflow Pipelines, or KFP, and\nTensorFlow Extended, or TFX.\n\n\n\n\n\n\nGenerative AI aims to solve general problems trained with amount of multimodal data.\nBehind it we have LLMs (Large Language Models) , the revolution starts in 2017 when Transformers was invented by Google Researchers.\n\n\nRefer to large, general-purpose language models can be pre-trained and then fine-tuned for specific purpose\n\nLarge :\n\nLarge training dataset PetaBytes\nLarge number of parameters trillions\n\nLLM are trained to solve :\n\nText classification\nQuestion answering\nDocument summarization\nText generation\n\n\n\n\n\n\nCreate :\n\nGenerate description from images\nImprove images\n\nSummarize:\n\nVideos, audio and paragraphs\nGeneate Q&A\n\nDiscover\n\nSearch for a document\nDiscover coding bugs\n\nAutomate\n\nExtract and label contracts\nclassify feedback and create ticket\n\n\n\n\n\nCode assistance provides AI-driven code assistance for cloud users such as application developers and data engineers.\n\n\n\nModel Garden is a single place to discover and interact with many of Google’s pre-trained and open-source models\nCategories of models\n\nFoundation models\n\nPaLM for text\nPaLM for chat\nImagen for image\nEmbeddings API for text and image\nChirp for speech\nCodey for code generation\n\nTask-specific solutions\n\nEntity analysis\nSentiment analysis\nSyntax analysis\nContent classification\nObject detector\nText translation\n\nFine-tunable or open-source models\n\n\n\n\nWe can use Generative AI Studio to quickly prototype and customize generative AI models with no or low code.\nThat support Language, Vision and Speech"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html",
    "href": "posts/2023-09-01-bigquery/index.html",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "Scenario:\nYour data analyst team exported the Google Analytics logs for an ecommerce website into BigQuery and created a new table of all the raw commerce visitor session data for you to explore. Using this data, you’ll try to answer a few questions.\nQuestion:\n\nOut of the total visitors who visited our website, what % made a purchase?\nWhat are the top 5 selling products?\nHow many visitors bought on subsequent visits to the website?\nLooking at the initial data results, do you think time_on_site and bounces will be a good indicator of whether the user will return and purchase or not?\n\n\n\nQuestion 1 : Out of the total visitors who visited our website, what % made a purchase?\nTo answer that question we gonig to dive total_purchasers / total_visitors :\nR: 2.69%\n#standardSQL\n\nWITH visitors AS(\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS total_visitors\nFROM `data-to-insights.ecommerce.web_analytics`\n),\npurchasers AS(\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS total_purchasers\nFROM `data-to-insights.ecommerce.web_analytics`\nWHERE totals.transactions IS NOT NULL\n)\nSELECT\n  total_visitors,\n  total_purchasers,\n  total_purchasers / total_visitors AS conversion_rate\nFROM visitors, purchasers\n\n\n\nQuestion 1\n\n\nQuestion 2 : What are the top 5 selling products?\nTo answer this question lets query and sum the productQuantity and return also the revenue\n\nSELECT\n  p.v2ProductName,\n  p.v2ProductCategory,\n  SUM(p.productQuantity) AS units_sold,\n  ROUND(SUM(p.localProductRevenue/1000000),2) AS revenue\nFROM `data-to-insights.ecommerce.web_analytics`,\nUNNEST(hits) AS h,\nUNNEST(h.product) AS p\nGROUP BY 1, 2\nORDER BY revenue DESC\nLIMIT 5;\n\n\n\n\nQuestion 2\n\n\nQuestion 3 : How many visitors bought on subsequent visits to the website?\nThis query will return two rows, one with total visitors that returned and buy and another one for not buy, the main logic in on that condition : IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n# visitors who bought on a return visit could have bought on first as well\n\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid, # 741,721 unique visitors\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\nSELECT\n  COUNT(DISTINCT fullvisitorid) AS total_visitors,\n  will_buy_on_return_visit\nFROM all_visitor_stats\nGROUP BY will_buy_on_return_visit\n\n\n\n\nQuesiton 3\n\n\n\n\n\nAfter explore the data lets create a dataset to create a Machine Learning model in BigQuery to predict whether or not a new user is likely to purchase in the future\nQuestion:: Looking at the initial data results, do you think time_on_site and bounces will be a good indicator of whether the user will return and purchase or not?\nIn the lab it was provided that there are two important fields for that prediction\n\ntotals.bounces (whether the visitor left the website immediately)\ntotals.timeOnSite (how long the visitor was on our website)\n\nSELECT\n  * EXCEPT(fullVisitorId)\nFROM\n  # features\n  (SELECT\n    fullVisitorId,\n    IFNULL(totals.bounces, 0) AS bounces,\n    IFNULL(totals.timeOnSite, 0) AS time_on_site\n  FROM\n    `data-to-insights.ecommerce.web_analytics`\n  WHERE\n    totals.newVisits = 1)\n  JOIN\n  (SELECT\n    fullvisitorid,\n    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n      `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid)\n  USING (fullVisitorId)\nORDER BY time_on_site DESC\nLIMIT 10;\n\n\n\n\nQuestion 4\n\n\n\n\n\n\nbefore run we need to create a dataset ecommerce to save the model\n\nCreate the model\nCREATE OR REPLACE MODEL `ecommerce.classification_model`\nOPTIONS\n(\nmodel_type='logistic_reg',\nlabels = ['will_buy_on_return_visit']\n)\nAS\n#standardSQL\nSELECT\n  * EXCEPT(fullVisitorId)\nFROM\n  # features\n  (SELECT\n    fullVisitorId,\n    IFNULL(totals.bounces, 0) AS bounces,\n    IFNULL(totals.timeOnSite, 0) AS time_on_site\n  FROM\n    `data-to-insights.ecommerce.web_analytics`\n  WHERE\n    totals.newVisits = 1\n    AND date BETWEEN '20160801' AND '20170430') # train on first 9 months\n  JOIN\n  (SELECT\n    fullvisitorid,\n    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n      `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid)\n  USING (fullVisitorId)\n;\n\n\n\n\nCreate the model\n\n\n\n\n\nIn his classificatin problem we need :\n\nminimize the False Positive Rate (predict that the user will return and purchase and they don’t)\nmaximize the True Positive Rate (predict that the user will return and purchase and they do)\n\nIn BigQuery ML, roc_auc is simply a queryable field when evaluating your trained ML model.\nSELECT\n  roc_auc,\n  CASE\n    WHEN roc_auc &gt; .9 THEN 'good'\n    WHEN roc_auc &gt; .8 THEN 'fair'\n    WHEN roc_auc &gt; .7 THEN 'not great'\n  ELSE 'poor' END AS model_quality\nFROM\n  ML.EVALUATE(MODEL ecommerce.classification_model,  (\nSELECT\n  * EXCEPT(fullVisitorId)\nFROM\n  # features\n  (SELECT\n    fullVisitorId,\n    IFNULL(totals.bounces, 0) AS bounces,\n    IFNULL(totals.timeOnSite, 0) AS time_on_site\n  FROM\n    `data-to-insights.ecommerce.web_analytics`\n  WHERE\n    totals.newVisits = 1\n    AND date BETWEEN '20170501' AND '20170630') # eval on 2 months\n  JOIN\n  (SELECT\n    fullvisitorid,\n    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n      `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid)\n  USING (fullVisitorId)\n));\n\n\n\nEvaluate\n\n\n\n\n\nAdd some new features and create a second machine learning model called classification_model_2:\n\nHow far the visitor got in the checkout process on their first visit\nWhere the visitor came from (traffic source: organic search, referring site etc.)\nDevice category (mobile, tablet, desktop)\nGeographic information (country)\n\nCreate the NEW model:\nCREATE OR REPLACE MODEL `ecommerce.classification_model_2`\nOPTIONS\n  (model_type='logistic_reg', labels = ['will_buy_on_return_visit']) AS\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid,\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\n# add in new features\nSELECT * EXCEPT(unique_session_id) FROM (\n  SELECT\n      CONCAT(fullvisitorid, CAST(visitId AS STRING)) AS unique_session_id,\n      # labels\n      will_buy_on_return_visit,\n      MAX(CAST(h.eCommerceAction.action_type AS INT64)) AS latest_ecommerce_progress,\n      # behavior on the site\n      IFNULL(totals.bounces, 0) AS bounces,\n      IFNULL(totals.timeOnSite, 0) AS time_on_site,\n      totals.pageviews,\n      # where the visitor came from\n      trafficSource.source,\n      trafficSource.medium,\n      channelGrouping,\n      # mobile or desktop\n      device.deviceCategory,\n      # geographic\n      IFNULL(geoNetwork.country, \"\") AS country\n  FROM `data-to-insights.ecommerce.web_analytics`,\n     UNNEST(hits) AS h\n    JOIN all_visitor_stats USING(fullvisitorid)\n  WHERE 1=1\n    # only predict for new visits\n    AND totals.newVisits = 1\n    AND date BETWEEN '20160801' AND '20170430' # train 9 months\n  GROUP BY\n  unique_session_id,\n  will_buy_on_return_visit,\n  bounces,\n  time_on_site,\n  totals.pageviews,\n  trafficSource.source,\n  trafficSource.medium,\n  channelGrouping,\n  device.deviceCategory,\n  country\n);\n\n\n\n\nNew Model\n\n\nEvaluate\n\n\n#standardSQL\nSELECT\n  roc_auc,\n  CASE\n    WHEN roc_auc &gt; .9 THEN 'good'\n    WHEN roc_auc &gt; .8 THEN 'fair'\n    WHEN roc_auc &gt; .7 THEN 'not great'\n  ELSE 'poor' END AS model_quality\nFROM\n  ML.EVALUATE(MODEL ecommerce.classification_model_2,  (\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid,\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\n# add in new features\nSELECT * EXCEPT(unique_session_id) FROM (\n  SELECT\n      CONCAT(fullvisitorid, CAST(visitId AS STRING)) AS unique_session_id,\n      # labels\n      will_buy_on_return_visit,\n      MAX(CAST(h.eCommerceAction.action_type AS INT64)) AS latest_ecommerce_progress,\n      # behavior on the site\n      IFNULL(totals.bounces, 0) AS bounces,\n      IFNULL(totals.timeOnSite, 0) AS time_on_site,\n      totals.pageviews,\n      # where the visitor came from\n      trafficSource.source,\n      trafficSource.medium,\n      channelGrouping,\n      # mobile or desktop\n      device.deviceCategory,\n      # geographic\n      IFNULL(geoNetwork.country, \"\") AS country\n  FROM `data-to-insights.ecommerce.web_analytics`,\n     UNNEST(hits) AS h\n    JOIN all_visitor_stats USING(fullvisitorid)\n  WHERE 1=1\n    # only predict for new visits\n    AND totals.newVisits = 1\n    AND date BETWEEN '20170501' AND '20170630' # eval 2 months\n  GROUP BY\n  unique_session_id,\n  will_buy_on_return_visit,\n  bounces,\n  time_on_site,\n  totals.pageviews,\n  trafficSource.source,\n  trafficSource.medium,\n  channelGrouping,\n  device.deviceCategory,\n  country\n)\n));\n\n\n\n\nEvaluate new model\n\n\n\n\n\nLets predict the probability that a first-time visitor will make a purchase in a later visit\nSELECT\n*\nFROM\n  ml.PREDICT(MODEL `ecommerce.classification_model_2`,\n   (\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid,\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\n  SELECT\n      CONCAT(fullvisitorid, '-',CAST(visitId AS STRING)) AS unique_session_id,\n      # labels\n      will_buy_on_return_visit,\n      MAX(CAST(h.eCommerceAction.action_type AS INT64)) AS latest_ecommerce_progress,\n      # behavior on the site\n      IFNULL(totals.bounces, 0) AS bounces,\n      IFNULL(totals.timeOnSite, 0) AS time_on_site,\n      totals.pageviews,\n      # where the visitor came from\n      trafficSource.source,\n      trafficSource.medium,\n      channelGrouping,\n      # mobile or desktop\n      device.deviceCategory,\n      # geographic\n      IFNULL(geoNetwork.country, \"\") AS country\n  FROM `data-to-insights.ecommerce.web_analytics`,\n     UNNEST(hits) AS h\n    JOIN all_visitor_stats USING(fullvisitorid)\n  WHERE\n    # only predict for new visits\n    totals.newVisits = 1\n    AND date BETWEEN '20170701' AND '20170801' # test 1 month\n  GROUP BY\n  unique_session_id,\n  will_buy_on_return_visit,\n  bounces,\n  time_on_site,\n  totals.pageviews,\n  trafficSource.source,\n  trafficSource.medium,\n  channelGrouping,\n  device.deviceCategory,\n  country\n)\n)\nORDER BY\n  predicted_will_buy_on_return_visit DESC;\n\n\n\n\nPredict\n\n\n\n\n\nUsing Deep learning and neural network :\n\nDeep Neural Network\nTensorFlow\n\nUsing AutoMl and XGBoost:\nAutoML\n\n\n\nauto_ml model\n\n\nXGBoost\n\n\n\nXGBoost model"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#exploring-the-data",
    "href": "posts/2023-09-01-bigquery/index.html#exploring-the-data",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "#standardSQL\nWITH visitors AS(\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS total_visitors\nFROM `data-to-insights.ecommerce.web_analytics`\n),\npurchasers AS(\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS total_purchasers\nFROM `data-to-insights.ecommerce.web_analytics`\nWHERE totals.transactions IS NOT NULL\n)\nSELECT\n  total_visitors,\n  total_purchasers,\n  total_purchasers / total_visitors AS conversion_rate\nFROM visitors, purchasers"
  },
  {
    "objectID": "posts/2022-09-30-first-cnn-model/index.html",
    "href": "posts/2022-09-30-first-cnn-model/index.html",
    "title": "Step by step to create a first computer vision model",
    "section": "",
    "text": "Kaggle notebook Application\n\n\nOn kaggle creare a notebook : File/New notebook\n\n\n\n\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\n\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\n\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\n\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\n\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\n\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\n\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\n\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\n\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\n\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\n\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "posts/2022-09-30-first-cnn-model/index.html#step-by-step-to-create-the-first-model",
    "href": "posts/2022-09-30-first-cnn-model/index.html#step-by-step-to-create-the-first-model",
    "title": "Step by step to create a first computer vision model",
    "section": "",
    "text": "Kaggle notebook Application\n\n\nOn kaggle creare a notebook : File/New notebook\n\n\n\n\nInstall fastai and gradio\n!pip install -Uqq fastai\n!pip install gradio\n\n\n\n\nImport fastai core and some libs\nfrom fastcore.all import *\nimport time\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport pathlib\n\n\n\nCreate a function to search images on DDG\ndef search_images(term, max_images=200):\n    url = 'https://duckduckgo.com/'\n    res = urlread(url,data={'q':term})\n    searchObj = re.search(r'vqd=([\\d-]+)\\&', res)\n    requestUrl = url + 'i.js'\n    params = dict(l='us-en', o='json', q=term, vqd=searchObj.group(1), f=',,,', p='1', v7exp='a')\n    urls,data = set(),{'next':1}\n    while len(urls)&lt;max_images and 'next' in data:\n        data = urljson(requestUrl,data=params)\n        urls.update(L(data['results']).itemgot('image'))\n        requestUrl = url + data['next']\n        time.sleep(0.2)\n    return L(urls)[:max_images]\n\n\n\nTry use the function and search for pictures that you are going to work for instance:\n\nbirds vs forest : to classify birds\nBlack vs grizzly vs ted bear\ndamage car vs car\nTypes of clouds : ‘cirrus’, ‘stratus’, ‘cumulus’\nis Michael jackson alive?\n\nMichael look alike person\nurls = search_images('look alike michael jackson', max_images=1)\n\ndest = 'FakeMichael.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\nMichael Jackson\ndownload_url(search_images('Michael jackson', max_images=1)[0], 'michael.jpg', show_progress=False)\nImage.open('michael.jpg').to_thumb(256,256)\n\n\n\n\nLets do a for loop to download more images\nsearches = 'Michael jackson','look alike michael jackson'\npath = Path('Michael_or_not')\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\n\n\n\nRemove failed images\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n\n\n\nCreate a data block\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\nLets create the learn or model and fine tune\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\nis_michael,_,probs = learn.predict(PILImage.create('FakeMichael.jpg'))\nprint(f\"This is a: {is_michael}.\")\nprint(f\"Probability He is Michael: {probs[0]:.4f}\")\nThis is a: look alike michael jackson. Probability He is Michael: 0.0086\n\n\n\nlearn.path = Path('.')\nlearn.export()\n\nTo Download from kaggle:\n\n\n\nDownload from kaggle\n\n\n\n\n\nAccess [huggingface.co)[https://huggingface.co/spaces], click in NEW and select Space, s this is similar github, add the name, select SDK gradio, hardware,license and create, after that you going to receive git clone command and instructions to create your gradio app.py\n\n\n\nCreate new spaces\n\n\n\n\n\n\nClone hugging face repo git clone &lt;repo&gt;\ncd &lt;repo_name&gt;\nCreate an app.py on the app you need to :\n\n\nimport libs\nload model\ncrete a list of categories\ncreate a function to classify, this function will call the .predict and perform the prediction\nCreate a button to input new images\nlanch the gradio interface\n\nSample\n__all__ = [ 'learn', 'classify_image', 'categories', 'image', 'label', 'examples', 'intf']\n\n# import libs\nfrom fastai.vision.all import *\nimport gradio as gr\n\n\n# load model\nlearn = load_learner('export.pkl')\n\n# list of categories\ncategories = ('Michael jackson', 'look alike michael jackson')\n\n## Classify func\ndef classify_image(img):\n    pred,idx,probs = learn.predict(img)\n    return dict(zip(categories, map(float,probs)))\n\n# input  new image\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['michael.jpg', 'fakemichael.jpg']\n\n## interface\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\n\nInput two sample images of each category\nCreate a requirements.txt to build the container with neecessary libs fastai and gradio\nCommit and add the files to repo, you will see something like :\n\n\n\n\nRepo\n\n\n\n\n\nIf the container has been create successfully you will see the app on APP link\n\n\n\nRepo\n\n\nTRY :\nis Michael alive ?"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#exploring-the-data-and-answer-the-questions",
    "href": "posts/2023-09-01-bigquery/index.html#exploring-the-data-and-answer-the-questions",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "Question 1 : Out of the total visitors who visited our website, what % made a purchase?\nTo answer that question we gonig to dive total_purchasers / total_visitors :\nR: 2.69%\n#standardSQL\n\nWITH visitors AS(\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS total_visitors\nFROM `data-to-insights.ecommerce.web_analytics`\n),\npurchasers AS(\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS total_purchasers\nFROM `data-to-insights.ecommerce.web_analytics`\nWHERE totals.transactions IS NOT NULL\n)\nSELECT\n  total_visitors,\n  total_purchasers,\n  total_purchasers / total_visitors AS conversion_rate\nFROM visitors, purchasers\n\n\n\nQuestion 1\n\n\nQuestion 2 : What are the top 5 selling products?\nTo answer this question lets query and sum the productQuantity and return also the revenue\n\nSELECT\n  p.v2ProductName,\n  p.v2ProductCategory,\n  SUM(p.productQuantity) AS units_sold,\n  ROUND(SUM(p.localProductRevenue/1000000),2) AS revenue\nFROM `data-to-insights.ecommerce.web_analytics`,\nUNNEST(hits) AS h,\nUNNEST(h.product) AS p\nGROUP BY 1, 2\nORDER BY revenue DESC\nLIMIT 5;\n\n\n\n\nQuestion 2\n\n\nQuestion 3 : How many visitors bought on subsequent visits to the website?\nThis query will return two rows, one with total visitors that returned and buy and another one for not buy, the main logic in on that condition : IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n# visitors who bought on a return visit could have bought on first as well\n\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid, # 741,721 unique visitors\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\nSELECT\n  COUNT(DISTINCT fullvisitorid) AS total_visitors,\n  will_buy_on_return_visit\nFROM all_visitor_stats\nGROUP BY will_buy_on_return_visit\n\n\n\n\nQuesiton 3"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#select-features-and-create-your-training-dataset",
    "href": "posts/2023-09-01-bigquery/index.html#select-features-and-create-your-training-dataset",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "After explore the data lets create a dataset to create a Machine Learning model in BigQuery to predict whether or not a new user is likely to purchase in the future\nQuestion:: Looking at the initial data results, do you think time_on_site and bounces will be a good indicator of whether the user will return and purchase or not?\nIn the lab it was provided that there are two important fields for that prediction\n\ntotals.bounces (whether the visitor left the website immediately)\ntotals.timeOnSite (how long the visitor was on our website)\n\nSELECT\n  * EXCEPT(fullVisitorId)\nFROM\n  # features\n  (SELECT\n    fullVisitorId,\n    IFNULL(totals.bounces, 0) AS bounces,\n    IFNULL(totals.timeOnSite, 0) AS time_on_site\n  FROM\n    `data-to-insights.ecommerce.web_analytics`\n  WHERE\n    totals.newVisits = 1)\n  JOIN\n  (SELECT\n    fullvisitorid,\n    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n      `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid)\n  USING (fullVisitorId)\nORDER BY time_on_site DESC\nLIMIT 10;\n\n\n\n\nQuestion 4"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#select-a-bigquery-ml-model-type-and-specify-options",
    "href": "posts/2023-09-01-bigquery/index.html#select-a-bigquery-ml-model-type-and-specify-options",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "before run we need to create a dataset ecommerce to save the model\n\nCreate the model\nCREATE OR REPLACE MODEL `ecommerce.classification_model`\nOPTIONS\n(\nmodel_type='logistic_reg',\nlabels = ['will_buy_on_return_visit']\n)\nAS\n#standardSQL\nSELECT\n  * EXCEPT(fullVisitorId)\nFROM\n  # features\n  (SELECT\n    fullVisitorId,\n    IFNULL(totals.bounces, 0) AS bounces,\n    IFNULL(totals.timeOnSite, 0) AS time_on_site\n  FROM\n    `data-to-insights.ecommerce.web_analytics`\n  WHERE\n    totals.newVisits = 1\n    AND date BETWEEN '20160801' AND '20170430') # train on first 9 months\n  JOIN\n  (SELECT\n    fullvisitorid,\n    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n      `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid)\n  USING (fullVisitorId)\n;\n\n\n\n\nCreate the model"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#evaluate-classification-model-performance",
    "href": "posts/2023-09-01-bigquery/index.html#evaluate-classification-model-performance",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "In his classificatin problem we need :\n\nminimize the False Positive Rate (predict that the user will return and purchase and they don’t)\nmaximize the True Positive Rate (predict that the user will return and purchase and they do)\n\nIn BigQuery ML, roc_auc is simply a queryable field when evaluating your trained ML model.\nSELECT\n  roc_auc,\n  CASE\n    WHEN roc_auc &gt; .9 THEN 'good'\n    WHEN roc_auc &gt; .8 THEN 'fair'\n    WHEN roc_auc &gt; .7 THEN 'not great'\n  ELSE 'poor' END AS model_quality\nFROM\n  ML.EVALUATE(MODEL ecommerce.classification_model,  (\nSELECT\n  * EXCEPT(fullVisitorId)\nFROM\n  # features\n  (SELECT\n    fullVisitorId,\n    IFNULL(totals.bounces, 0) AS bounces,\n    IFNULL(totals.timeOnSite, 0) AS time_on_site\n  FROM\n    `data-to-insights.ecommerce.web_analytics`\n  WHERE\n    totals.newVisits = 1\n    AND date BETWEEN '20170501' AND '20170630') # eval on 2 months\n  JOIN\n  (SELECT\n    fullvisitorid,\n    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n      `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid)\n  USING (fullVisitorId)\n));\n\n\n\nEvaluate"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#improve-model-performance-with-feature-engineering",
    "href": "posts/2023-09-01-bigquery/index.html#improve-model-performance-with-feature-engineering",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "Add some new features and create a second machine learning model called classification_model_2:\n\nHow far the visitor got in the checkout process on their first visit\nWhere the visitor came from (traffic source: organic search, referring site etc.)\nDevice category (mobile, tablet, desktop)\nGeographic information (country)\n\nCreate the NEW model:\nCREATE OR REPLACE MODEL `ecommerce.classification_model_2`\nOPTIONS\n  (model_type='logistic_reg', labels = ['will_buy_on_return_visit']) AS\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid,\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\n# add in new features\nSELECT * EXCEPT(unique_session_id) FROM (\n  SELECT\n      CONCAT(fullvisitorid, CAST(visitId AS STRING)) AS unique_session_id,\n      # labels\n      will_buy_on_return_visit,\n      MAX(CAST(h.eCommerceAction.action_type AS INT64)) AS latest_ecommerce_progress,\n      # behavior on the site\n      IFNULL(totals.bounces, 0) AS bounces,\n      IFNULL(totals.timeOnSite, 0) AS time_on_site,\n      totals.pageviews,\n      # where the visitor came from\n      trafficSource.source,\n      trafficSource.medium,\n      channelGrouping,\n      # mobile or desktop\n      device.deviceCategory,\n      # geographic\n      IFNULL(geoNetwork.country, \"\") AS country\n  FROM `data-to-insights.ecommerce.web_analytics`,\n     UNNEST(hits) AS h\n    JOIN all_visitor_stats USING(fullvisitorid)\n  WHERE 1=1\n    # only predict for new visits\n    AND totals.newVisits = 1\n    AND date BETWEEN '20160801' AND '20170430' # train 9 months\n  GROUP BY\n  unique_session_id,\n  will_buy_on_return_visit,\n  bounces,\n  time_on_site,\n  totals.pageviews,\n  trafficSource.source,\n  trafficSource.medium,\n  channelGrouping,\n  device.deviceCategory,\n  country\n);\n\n\n\n\nNew Model\n\n\nEvaluate\n\n\n#standardSQL\nSELECT\n  roc_auc,\n  CASE\n    WHEN roc_auc &gt; .9 THEN 'good'\n    WHEN roc_auc &gt; .8 THEN 'fair'\n    WHEN roc_auc &gt; .7 THEN 'not great'\n  ELSE 'poor' END AS model_quality\nFROM\n  ML.EVALUATE(MODEL ecommerce.classification_model_2,  (\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid,\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\n# add in new features\nSELECT * EXCEPT(unique_session_id) FROM (\n  SELECT\n      CONCAT(fullvisitorid, CAST(visitId AS STRING)) AS unique_session_id,\n      # labels\n      will_buy_on_return_visit,\n      MAX(CAST(h.eCommerceAction.action_type AS INT64)) AS latest_ecommerce_progress,\n      # behavior on the site\n      IFNULL(totals.bounces, 0) AS bounces,\n      IFNULL(totals.timeOnSite, 0) AS time_on_site,\n      totals.pageviews,\n      # where the visitor came from\n      trafficSource.source,\n      trafficSource.medium,\n      channelGrouping,\n      # mobile or desktop\n      device.deviceCategory,\n      # geographic\n      IFNULL(geoNetwork.country, \"\") AS country\n  FROM `data-to-insights.ecommerce.web_analytics`,\n     UNNEST(hits) AS h\n    JOIN all_visitor_stats USING(fullvisitorid)\n  WHERE 1=1\n    # only predict for new visits\n    AND totals.newVisits = 1\n    AND date BETWEEN '20170501' AND '20170630' # eval 2 months\n  GROUP BY\n  unique_session_id,\n  will_buy_on_return_visit,\n  bounces,\n  time_on_site,\n  totals.pageviews,\n  trafficSource.source,\n  trafficSource.medium,\n  channelGrouping,\n  device.deviceCategory,\n  country\n)\n));\n\n\n\n\nEvaluate new model"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#predict-which-new-visitors-will-come-back-and-purchase",
    "href": "posts/2023-09-01-bigquery/index.html#predict-which-new-visitors-will-come-back-and-purchase",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "Lets predict the probability that a first-time visitor will make a purchase in a later visit\nSELECT\n*\nFROM\n  ml.PREDICT(MODEL `ecommerce.classification_model_2`,\n   (\nWITH all_visitor_stats AS (\nSELECT\n  fullvisitorid,\n  IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, 1, 0) AS will_buy_on_return_visit\n  FROM `data-to-insights.ecommerce.web_analytics`\n  GROUP BY fullvisitorid\n)\n  SELECT\n      CONCAT(fullvisitorid, '-',CAST(visitId AS STRING)) AS unique_session_id,\n      # labels\n      will_buy_on_return_visit,\n      MAX(CAST(h.eCommerceAction.action_type AS INT64)) AS latest_ecommerce_progress,\n      # behavior on the site\n      IFNULL(totals.bounces, 0) AS bounces,\n      IFNULL(totals.timeOnSite, 0) AS time_on_site,\n      totals.pageviews,\n      # where the visitor came from\n      trafficSource.source,\n      trafficSource.medium,\n      channelGrouping,\n      # mobile or desktop\n      device.deviceCategory,\n      # geographic\n      IFNULL(geoNetwork.country, \"\") AS country\n  FROM `data-to-insights.ecommerce.web_analytics`,\n     UNNEST(hits) AS h\n    JOIN all_visitor_stats USING(fullvisitorid)\n  WHERE\n    # only predict for new visits\n    totals.newVisits = 1\n    AND date BETWEEN '20170701' AND '20170801' # test 1 month\n  GROUP BY\n  unique_session_id,\n  will_buy_on_return_visit,\n  bounces,\n  time_on_site,\n  totals.pageviews,\n  trafficSource.source,\n  trafficSource.medium,\n  channelGrouping,\n  device.deviceCategory,\n  country\n)\n)\nORDER BY\n  predicted_will_buy_on_return_visit DESC;\n\n\n\n\nPredict"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#results",
    "href": "posts/2023-09-01-bigquery/index.html#results",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "Of the top 6% of first-time visitors (sorted in decreasing order of predicted probability), more than 6% make a purchase in a later visit.\nThese users represent nearly 50% of all first-time visitors who make a purchase in a later visit.\nOverall, only 0.7% of first-time visitors make a purchase in a later visit.\nTargeting the top 6% of first-time increases marketing ROI by 9x vs targeting them all!"
  },
  {
    "objectID": "posts/2023-09-01-bigquery/index.html#more-options-to-create-model",
    "href": "posts/2023-09-01-bigquery/index.html#more-options-to-create-model",
    "title": "Predicting Visitor Purchases with BigQuery ML",
    "section": "",
    "text": "Using Deep learning and neural network :\n\nDeep Neural Network\nTensorFlow\n\nUsing AutoMl and XGBoost:\nAutoML\n\n\n\nauto_ml model\n\n\nXGBoost\n\n\n\nXGBoost model"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#clean-the-data",
    "href": "notas/2023-09-01-deep-learning/index.html#clean-the-data",
    "title": "Deep learning for Coders fast.ai",
    "section": "Clean the data",
    "text": "Clean the data\n\nBefore clean the data train the model ?\n\n\nDiffent ways to resize and transform the image (this is in-memory image transformation)\n\nResizeMethod.Squish : Make sure we can see the whole picture\nResizeMethod.Pad, pad_mode='zeros' : can see the whole image with better ratio\nRandomResizeCrop : Different bits (crop/size) of image each time it is called Data Augmentation, can also use aug_transforms()\n\nConfusion Matrix\n\nWe can use the confustion matrix to identify the hardiest category to identify/classify\nOn fastai there are the ClassificationInterpretation object that will generate the Confusion Matrix\n\n\ninterp = ClassificationInterpretation.from_learn(lern)\ninterp.plot_confusion_matrix()\n\nWe can plot Top Losses It tells us the places where the loss is the highest\n\ninterp = ClassificationInterpretation.from_learn(lern)\ninterp.plot_top_losses(5, nrows=1, figsize=(17,4))\n\nAfter use those functions we can call ImageClassifierCleaner() to clean up the ones that are wrongly label on dataset and remove from dataset\n\n\n\n\n\n\n\nTip\n\n\n\nBefore we clean up the dataset, always build a model to find out what things are difficult to recognize in your dataset and to find the things that the model can help you find data problems"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#whch-image-models-are-best",
    "href": "notas/2023-09-01-deep-learning/index.html#whch-image-models-are-best",
    "title": "Deep learning for Coders fast.ai",
    "section": "Whch image models are best ?",
    "text": "Whch image models are best ?\nThe kaggle notebook Which image models are best\nPyTorch Image Models (timm) is a library by Ross Wightman which provides state-of-the-art pre-trained computer vision models.\nTo use timm we need :\n\nInstall : conda install timm or pip install timm\nImport : import timm\nSample of list convnext models: timm.list_models('convnext')"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#understand-the-model",
    "href": "notas/2023-09-01-deep-learning/index.html#understand-the-model",
    "title": "Deep learning for Coders fast.ai",
    "section": "Understand the model",
    "text": "Understand the model\n\nCategories : fast.ai always save the vocab or categories inside the data loaders learn.dls.vocab\nWhat is model.pkl file ?\n\nThe model or learn there are two main things :\n\nThe list of pre-processing steps to prepare your image to model\nThe trained model, the arquitecture or layers\n\nThe below model was trained based on resnet18\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)\n\n\nTo check detail about one layer we can use get_submodule from pyTorch, so lets check 0.4.0.conv1 layer\n\nl = learn.model.get_submodule('0.4.0.conv1')\nl\nOutput:\nConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\nParameters\nlist(l.parameters())\nOuput is a tensor:\n[Parameter containing:\n tensor([[[[ 5.7570e-02, -9.5167e-02, -2.0318e-02],\n           [-7.4519e-02, -7.9924e-01, -2.1283e-01],\n           [ 6.5605e-02, -9.6507e-02, -1.2085e-02]],\n \n          [[-6.9990e-03,  1.4247e-02,  5.3876e-04],\n           [ 4.1250e-02, -1.6123e-01, -2.3197e-02],\n           [ 3.2788e-03,  7.1502e-03,  7.1681e-02]],\n \n          [[-2.3627e-09, -3.9269e-08, -3.2971e-08],\n           [ 2.1737e-08,  8.3299e-09,  1.2543e-08],\n           [ 1.1381e-08,  8.8095e-09,  1.5506e-08]],\n \n          ...,\n\nLoss function:\nIs the function that calculate the error metric that we would minimize\nSample:\nMSE\ndef mse(preds, acts): return ((preds - acts)**2).mean()\nHow do we minimize the loss function ? \n\nWe can change the parameters and see if loss improves\nOr use derivative, basically derivative tells you : if you increase the input, your output increase or decrease this is the slope or gradient\nTo request pyTorch to calculate the gradient just need to set requires_grad() to a tensor\nIf we call loss.backward() It will calculate the gradient on the result of loss function\n\n\n\nLearning Rate\nis a Hyperparameter that we use to calculate parameters\nOptimization - Gradient descent\n\nThe goal is minimize the loss function by deacrease this gradient multiplying by a small number such as 0.01 this number is the Learning rate\nOn the end of process we end up with a small loss\n\n\n\nIf learning rate is two small, it will take so long time to try to converge\nIf learning rate is two big will never converge\n\nOptimization - Gradient descent\n\nThe goal is minimize the loss function by deacrease this gradient multiplying by a small number such as 0.01 this number is the Learning rate\nOn the end of process we end up with a small loss\n\n\n\n\nReLU\ndef rectified_liner(m,b,x):\n  y = m*x+b\n  return torch.clip(y, 0.)\nWith this function we can use double or more ReLu and manipulate more dimmendations and construct a precise model\n\n\nMatrix Multiplication\nHow to do a marix multiplication matrixmultiplication.xyz\nTitanic on excel"
  },
  {
    "objectID": "notas/2023-10-13-AWS Machine Learning/index.html",
    "href": "notas/2023-10-13-AWS Machine Learning/index.html",
    "title": "AWS Machine Learning – Specialty",
    "section": "",
    "text": "ML Definition : A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at ask in T, as measured by P, improves with experience E\n\nML apply to many business use cases :\nIndustry : * Recomendation * Demand forecast * Computer Vision * Fraud Detection * Medical Diagosis * Stock Market Forecasting * Sentiment Analysis\nTypes: * Supervised : classification and regression * Unsupervised : clustering, anomaly detection, association discovery\nML Algorithms * Logistic Regression : Binary classification * Decision Trees * Naive Bayes : Probability based\n\n\n\nDomain 1 : Data Engineering create repo, data-ingestion, data-transformation Domain 2 : Exploratory Data Analysis prep data for modelin, feature engineering, and data viz for ML Domain 3 : Modeling frame business problem as ML problems, select model, train ML, perform hyperparamter optimization, evaluate model Domain 4 : ML Implementation and Operations build and deploy ML solutions"
  },
  {
    "objectID": "notas/2023-10-13-AWS Machine Learning/index.html#intro-do-machine-learning-concepts",
    "href": "notas/2023-10-13-AWS Machine Learning/index.html#intro-do-machine-learning-concepts",
    "title": "AWS Machine Learning – Specialty",
    "section": "",
    "text": "ML Definition : A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at ask in T, as measured by P, improves with experience E\n\nML apply to many business use cases :\nIndustry : * Recomendation * Demand forecast * Computer Vision * Fraud Detection * Medical Diagosis * Stock Market Forecasting * Sentiment Analysis\nTypes: * Supervised : classification and regression * Unsupervised : clustering, anomaly detection, association discovery\nML Algorithms * Logistic Regression : Binary classification * Decision Trees * Naive Bayes : Probability based"
  },
  {
    "objectID": "notas/2023-10-13-AWS Machine Learning/index.html#domain",
    "href": "notas/2023-10-13-AWS Machine Learning/index.html#domain",
    "title": "AWS Machine Learning – Specialty",
    "section": "",
    "text": "Domain 1 : Data Engineering create repo, data-ingestion, data-transformation Domain 2 : Exploratory Data Analysis prep data for modelin, feature engineering, and data viz for ML Domain 3 : Modeling frame business problem as ML problems, select model, train ML, perform hyperparamter optimization, evaluate model Domain 4 : ML Implementation and Operations build and deploy ML solutions"
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#overfitting-and-validationtest-dataset",
    "href": "notas/2023-09-01-deep-learning/index.html#overfitting-and-validationtest-dataset",
    "title": "Deep learning for Coders fast.ai",
    "section": "Overfitting and Validation/Test dataset",
    "text": "Overfitting and Validation/Test dataset\n\nIn time series instead of remove data from the middle it is better to truncate the last weeks\nFastai will show the metrics from validation dataset\nHow (and why) to create a good validation set"
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-1-architecting-low-code-ml-solutions-12-of-the-exam",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-1-architecting-low-code-ml-solutions-12-of-the-exam",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "1.1 Developing ML models by using BigQuery ML\n\nBigQuery is fully managed DW, that can analyse data using SQL, i.e, use SQL to create and execute ML models in BigQuery\nWe can perform both data analytics and build ML models within BigQuery\nBigQuery ML tunes the parameters for you and helps you manage the ML workflow, also perform some pre-procesing like One-Hot Encoding\nWe create the model inside BigQuery\n\nLAB\nPredicting Visitor Purchases with BigQuery ML\nTo read\n\nBig Query intro\nBig Query Syntax\n\n1.2 Building AI solutions by using ML APIs.\nGCP has several pre-trained machine learn models that can be used by API(application programming interface)\nPre-trained API offered as a services:\n\n\n\nPre-trained API\n\n\n1.3 Training models by using AutoML.\nAutoML apply a non-code solution to build models on VertexAI"
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/temp.html",
    "href": "notas/2023-09-06-GCP-ML-Engineer/temp.html",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "This course provide a toolbox which is full of AI tecnologies and tools offered by Google\n\nFoundation : cloud essentials\nDevelopement : different options to build ML and Workflow\nSolutions :Vertical and horizontal solutions and generative AI\n\n\n\n\n\nGoogle is a leader in developement of AI and it offers a wide range of tools\nand provides :\n\nState-of-the-art ML models\nEnd-to-end model development and MLOps - Productivity\nUnified data to AI plataform\nEfficient and scalable AI - Infrastructure\n\n7 principals AI should be:\n\nsocially beneficial\nAvoid creating or reinforcing unfair bias\nBuild and tested for safety\nAccountable to people\nIncorporate privancy design principles\nUphold high standards of scientific excelence\nMade available for uses that accord with these principles\n\n\n\n\n\nComputer Engine : IaaS with compute , storage, network similar to a phisical machine\nGoogle Kubernetes Engine : Containerized applications\nApp Engine : PaaS, binds code to libraries and developed can be focused on appl logic\nCloud Functions : Executes code in response to events. Functions as a services\nCloud Run : Fully managed platform, auto scales up and down, charge only by resources you use\n\n\n\n\nCPU : Central processing unit\nGPU : Graphics processing unit\nTPU : Tensor Processing Unit\n\n\n\n\n\n\n\nTPU\n\n\n\nTPU are faster and more energy-efficient for AI and ML applications.\nThis is the state-of-the-art hardware and supercomputing technology is available with Google Cloud products and services\n\n\n\n\n\n\nHow to choose from these products and services ?\n\nIt depends of data type and bussiness needs\nUnstructured data\n\nCloud Storage\n\nStandard storage - Hot data\nNearline storage - Once per month\nColdline storage - Once every 90 days\nArchive storage - Once a year\n\n\nStructure data\n\nTransactional\n\nSQL\n\nlocal/reginal : Cloud SQL\nglobal : Cloud spanner\n\nNoSQL : Firestore\n\nAnalytical\n\nSQL : BigQuery\nNOSQL : Cloud Bigtable\n\n\n\n\n\n\nProducts available in each stage of the data-to-AI workflow\n\nIngestion and processing : (Pub/Sub, Dataflow, Dataproc and Cloud Data Fusion)\nStorage : (CloudSQL, Cloud Spanner, Cloud BigTable and Firestore)\nAnalytics : (BigQuery and looker)\nAI/ML : (VertexAI)\n\n\n\n\nAI includes anything related to computer mimicking human intelligence (Robts and self-driving cars)\nMachine Learning is a subset of AI that allows computers to learn without being explicity programmed\n\n\n\n\nWith BigQuery ML, you can manage the tabular data and execute ML models in one place with just a few steps\nKey phases of Machine Learning project\n\nExtract, transform, and load data into BigQuery\nSelect and preprocess featres\n\n\nBigQuery ML does some preprocessing for us, like one-hot encoding\n\n\nCreate the model\n\n#standarSQL\n\nCREATE MODEL\necommerce.classification\n\nOPTIONS\n(\n  model_type='logistic_reg'\n  input_label_cols='will_buy_later'\n\n) AS \n\n# SQL with training data\n\nThere are others algorithms :\n\n\n\nBigQuery Model Selection\n\n\n\nEvaluate the performance of the trained model\n\nSELECT \n  roc_auc,\n  accuracy,\n  precision,\n  recall\nFROM \n  ML.EVALUATE(MODEL`ecommerce.classification`)\n\nUse the model to make predictions\n\nSELECT * FROM\n  ML.PREDICT\n  (\n    MODEL.`ecommerce.classification` )\n\n\n\n\n\nGoogle offers to build a machine learning models\n\nPre-trained APIs : Use ML models that google already built and trained\nBigQuery ML : Use SQL queries to create and execute ML models in BigQuery\nAutoML : Apply no-code solution to build ml models on Vertex AI\nCustom training : Code your own ML env to have the control over the ML pipeline\n\n\n\nAPI (Application Programming Interface) define how software components communicate with each other.\n\nCloud Natural Language API : recognizes parts of speech called entities and sentiment.\nCloud Speech-to-Text : convert audio to text\nCloud Translation API : convert text from one language to another\nCloud Vision : recognizes content in static images\nCloud Video Intelligence : recognizes motion and actions in a video\nDiagflow API : builds conversational interfaces\nGenerative AI related APIs :\n\nPaLM for text : perform language tasks and tune the LLM model with your own data.\nPaLM for chat : create applications that engage users in dynamic and context-aware conversations.\nImage for image : create and edit images\nEmbeddings API for text and Image : extract semantic information from unstructured data.\nChirp for speech : build voice\nCody for code generation : produce and debug code\n\nNatural Language API\n\nTry - demo\n\n\n\n\n\nVertex AI provides an end-to-end ML, pipeline to prepare data, and create, deploy, and manage models over time, and at scale.\nWe can think of Vertex AI Workbench as a Jupyter notebook deployed in a single development environment\n\n\n\nAutomate the process to develop and deploy an ML model.\nAutoML automates the pipeline from feature ngineering, to architecture search, to hyperparameter tuning, and to model ensembly\n\n\n\nDo-it-yourself solution to build an ML project.\nWhich environment you want your ML training code to use.\n\npre-built container\ncustom container\n\nCan use ML Library (TensorFlow, scikit-learn, and PyTorch.) collection of pre-written code that can be used to perform machine learning tasks.\nTensorFlow\n\n\n\n\n\n\n\n\n\nThere are several types of Neural Networks that solves different problems\n\nANN artificial neural network\nDNN deep neural network\nCNN convolutional neural network\nRNN recurrent neural network\nLLM large language models\n\nSTEP 1 : calculate the weighted sum multiplying each input value by its corresponding weight, and then summing the products\n\nSTEP 2: apply an activation function to the weighted sum.\n\nSTEP 3 : the weighted sum is calculated for the output layer\nSTEP 4 : apply an activation function to the weighted sum\n\nSTEP 5 : calculate the cost function to minimize the difference.\n\nCost functions for : * regression (MSE) * classfication (Cross-entropy)\nSTEP 6: backpropagation\nif the difference between the predicted and actual results is significant, you must go back to adjust weights and biases to minimize the cost function.\n\nSTEP 7: Interate the process (epoch)\n\n\nwe can set the number of epochs as a hyperparameter in training\nwe can tell that the cost function has reached its optimum when the value stops decreasing, even after many iterations.\n\n\nThis is how a neural network learns : It iterates the learning by continuously adjusting weights to improve behavior until it reaches the best result.\n\n\n\n\nactivation function is used to prevent linearity or add non-linearity.\n\n\nReLU\nSigmoid : binary classfication\nSoftmax : multi-class classification\nTanH\netc …\n\n\n\n\n\nStages :\n\nData preparation (Upload data and Feature engineer)\nModel development\nModel serving\n\n\n\n\nDuring this stage, you must upload data and then prepare it for model training with feature engineering.\n\nfeature engineering: the data must be processed before the model starts training.\nVertex AI provides a function called Vertex AI Feature Store, which is a centralized repository to organize, store, and serve features.\n\n\n\n\nAfter data is ready it is time to training the model, this stage involves two iterative steps :\n\nModel training\nModel evaluation\n\nVertex AI provides extensive evaluation metrics to help determine a model’s performance. A confusion matrix is a specific performance measurement for machine learning classification problems.\n\nRecall : refers to all the positive cases, and looks at how many were predicted correctly. Precision : refers to all the cases predicted as positive, and how many are actually positive.\n\n\n\n\nOn this stage we have two steps :\n\nDeploy model\nMonitor the model\n\nThere are 3 options to deploy a model\n\nEndpoint\nBatch prediction\nOffline prediction\n\nTo monitor there are a toolkit Vertex AI Pipelines\n\n\n\n\nMLOps means automating and monitoring each step of the ML system construction to enable continuous integration, training, and delivery.\n\n\nMLOps on Vertex AI is a tool kit called Vertex AI Pipelines that supports :\n\nKubeflow Pipelines, or KFP, and\nTensorFlow Extended, or TFX.\n\n\n\n\n\n\nGenerative AI aims to solve general problems trained with amount of multimodal data.\nBehind it we have LLMs (Large Language Models) , the revolution starts in 2017 when Transformers was invented by Google Researchers.\n\n\nRefer to large, general-purpose language models can be pre-trained and then fine-tuned for specific purpose\n\nLarge :\n\nLarge training dataset PetaBytes\nLarge number of parameters trillions\n\nLLM are trained to solve :\n\nText classification\nQuestion answering\nDocument summarization\nText generation\n\n\n\n\n\n\nCreate :\n\nGenerate description from images\nImprove images\n\nSummarize:\n\nVideos, audio and paragraphs\nGeneate Q&A\n\nDiscover\n\nSearch for a document\nDiscover coding bugs\n\nAutomate\n\nExtract and label contracts\nclassify feedback and create ticket\n\n\n\n\n\nCode assistance provides AI-driven code assistance for cloud users such as application developers and data engineers.\n\n\n\nModel Garden is a single place to discover and interact with many of Google’s pre-trained and open-source models\nCategories of models\n\nFoundation models\n\nPaLM for text\nPaLM for chat\nImagen for image\nEmbeddings API for text and image\nChirp for speech\nCodey for code generation\n\nTask-specific solutions\n\nEntity analysis\nSentiment analysis\nSyntax analysis\nContent classification\nObject detector\nText translation\n\nFine-tunable or open-source models\n\n\n\n\nWe can use Generative AI Studio to quickly prototype and customize generative AI models with no or low code.\nThat support Language, Vision and Speech"
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/temp.html#introduction-to-ai-and-machine-learning",
    "href": "notas/2023-09-06-GCP-ML-Engineer/temp.html#introduction-to-ai-and-machine-learning",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "This course provide a toolbox which is full of AI tecnologies and tools offered by Google\n\nFoundation : cloud essentials\nDevelopement : different options to build ML and Workflow\nSolutions :Vertical and horizontal solutions and generative AI\n\n\n\n\n\nGoogle is a leader in developement of AI and it offers a wide range of tools\nand provides :\n\nState-of-the-art ML models\nEnd-to-end model development and MLOps - Productivity\nUnified data to AI plataform\nEfficient and scalable AI - Infrastructure\n\n7 principals AI should be:\n\nsocially beneficial\nAvoid creating or reinforcing unfair bias\nBuild and tested for safety\nAccountable to people\nIncorporate privancy design principles\nUphold high standards of scientific excelence\nMade available for uses that accord with these principles\n\n\n\n\n\nComputer Engine : IaaS with compute , storage, network similar to a phisical machine\nGoogle Kubernetes Engine : Containerized applications\nApp Engine : PaaS, binds code to libraries and developed can be focused on appl logic\nCloud Functions : Executes code in response to events. Functions as a services\nCloud Run : Fully managed platform, auto scales up and down, charge only by resources you use\n\n\n\n\nCPU : Central processing unit\nGPU : Graphics processing unit\nTPU : Tensor Processing Unit\n\n\n\n\n\n\n\nTPU\n\n\n\nTPU are faster and more energy-efficient for AI and ML applications.\nThis is the state-of-the-art hardware and supercomputing technology is available with Google Cloud products and services\n\n\n\n\n\n\nHow to choose from these products and services ?\n\nIt depends of data type and bussiness needs\nUnstructured data\n\nCloud Storage\n\nStandard storage - Hot data\nNearline storage - Once per month\nColdline storage - Once every 90 days\nArchive storage - Once a year\n\n\nStructure data\n\nTransactional\n\nSQL\n\nlocal/reginal : Cloud SQL\nglobal : Cloud spanner\n\nNoSQL : Firestore\n\nAnalytical\n\nSQL : BigQuery\nNOSQL : Cloud Bigtable\n\n\n\n\n\n\nProducts available in each stage of the data-to-AI workflow\n\nIngestion and processing : (Pub/Sub, Dataflow, Dataproc and Cloud Data Fusion)\nStorage : (CloudSQL, Cloud Spanner, Cloud BigTable and Firestore)\nAnalytics : (BigQuery and looker)\nAI/ML : (VertexAI)\n\n\n\n\nAI includes anything related to computer mimicking human intelligence (Robts and self-driving cars)\nMachine Learning is a subset of AI that allows computers to learn without being explicity programmed\n\n\n\n\nWith BigQuery ML, you can manage the tabular data and execute ML models in one place with just a few steps\nKey phases of Machine Learning project\n\nExtract, transform, and load data into BigQuery\nSelect and preprocess featres\n\n\nBigQuery ML does some preprocessing for us, like one-hot encoding\n\n\nCreate the model\n\n#standarSQL\n\nCREATE MODEL\necommerce.classification\n\nOPTIONS\n(\n  model_type='logistic_reg'\n  input_label_cols='will_buy_later'\n\n) AS \n\n# SQL with training data\n\nThere are others algorithms :\n\n\n\nBigQuery Model Selection\n\n\n\nEvaluate the performance of the trained model\n\nSELECT \n  roc_auc,\n  accuracy,\n  precision,\n  recall\nFROM \n  ML.EVALUATE(MODEL`ecommerce.classification`)\n\nUse the model to make predictions\n\nSELECT * FROM\n  ML.PREDICT\n  (\n    MODEL.`ecommerce.classification` )\n\n\n\n\n\nGoogle offers to build a machine learning models\n\nPre-trained APIs : Use ML models that google already built and trained\nBigQuery ML : Use SQL queries to create and execute ML models in BigQuery\nAutoML : Apply no-code solution to build ml models on Vertex AI\nCustom training : Code your own ML env to have the control over the ML pipeline\n\n\n\nAPI (Application Programming Interface) define how software components communicate with each other.\n\nCloud Natural Language API : recognizes parts of speech called entities and sentiment.\nCloud Speech-to-Text : convert audio to text\nCloud Translation API : convert text from one language to another\nCloud Vision : recognizes content in static images\nCloud Video Intelligence : recognizes motion and actions in a video\nDiagflow API : builds conversational interfaces\nGenerative AI related APIs :\n\nPaLM for text : perform language tasks and tune the LLM model with your own data.\nPaLM for chat : create applications that engage users in dynamic and context-aware conversations.\nImage for image : create and edit images\nEmbeddings API for text and Image : extract semantic information from unstructured data.\nChirp for speech : build voice\nCody for code generation : produce and debug code\n\nNatural Language API\n\nTry - demo\n\n\n\n\n\nVertex AI provides an end-to-end ML, pipeline to prepare data, and create, deploy, and manage models over time, and at scale.\nWe can think of Vertex AI Workbench as a Jupyter notebook deployed in a single development environment\n\n\n\nAutomate the process to develop and deploy an ML model.\nAutoML automates the pipeline from feature ngineering, to architecture search, to hyperparameter tuning, and to model ensembly\n\n\n\nDo-it-yourself solution to build an ML project.\nWhich environment you want your ML training code to use.\n\npre-built container\ncustom container\n\nCan use ML Library (TensorFlow, scikit-learn, and PyTorch.) collection of pre-written code that can be used to perform machine learning tasks.\nTensorFlow\n\n\n\n\n\n\n\n\n\nThere are several types of Neural Networks that solves different problems\n\nANN artificial neural network\nDNN deep neural network\nCNN convolutional neural network\nRNN recurrent neural network\nLLM large language models\n\nSTEP 1 : calculate the weighted sum multiplying each input value by its corresponding weight, and then summing the products\n\nSTEP 2: apply an activation function to the weighted sum.\n\nSTEP 3 : the weighted sum is calculated for the output layer\nSTEP 4 : apply an activation function to the weighted sum\n\nSTEP 5 : calculate the cost function to minimize the difference.\n\nCost functions for : * regression (MSE) * classfication (Cross-entropy)\nSTEP 6: backpropagation\nif the difference between the predicted and actual results is significant, you must go back to adjust weights and biases to minimize the cost function.\n\nSTEP 7: Interate the process (epoch)\n\n\nwe can set the number of epochs as a hyperparameter in training\nwe can tell that the cost function has reached its optimum when the value stops decreasing, even after many iterations.\n\n\nThis is how a neural network learns : It iterates the learning by continuously adjusting weights to improve behavior until it reaches the best result.\n\n\n\n\nactivation function is used to prevent linearity or add non-linearity.\n\n\nReLU\nSigmoid : binary classfication\nSoftmax : multi-class classification\nTanH\netc …\n\n\n\n\n\nStages :\n\nData preparation (Upload data and Feature engineer)\nModel development\nModel serving\n\n\n\n\nDuring this stage, you must upload data and then prepare it for model training with feature engineering.\n\nfeature engineering: the data must be processed before the model starts training.\nVertex AI provides a function called Vertex AI Feature Store, which is a centralized repository to organize, store, and serve features.\n\n\n\n\nAfter data is ready it is time to training the model, this stage involves two iterative steps :\n\nModel training\nModel evaluation\n\nVertex AI provides extensive evaluation metrics to help determine a model’s performance. A confusion matrix is a specific performance measurement for machine learning classification problems.\n\nRecall : refers to all the positive cases, and looks at how many were predicted correctly. Precision : refers to all the cases predicted as positive, and how many are actually positive.\n\n\n\n\nOn this stage we have two steps :\n\nDeploy model\nMonitor the model\n\nThere are 3 options to deploy a model\n\nEndpoint\nBatch prediction\nOffline prediction\n\nTo monitor there are a toolkit Vertex AI Pipelines\n\n\n\n\nMLOps means automating and monitoring each step of the ML system construction to enable continuous integration, training, and delivery.\n\n\nMLOps on Vertex AI is a tool kit called Vertex AI Pipelines that supports :\n\nKubeflow Pipelines, or KFP, and\nTensorFlow Extended, or TFX.\n\n\n\n\n\n\nGenerative AI aims to solve general problems trained with amount of multimodal data.\nBehind it we have LLMs (Large Language Models) , the revolution starts in 2017 when Transformers was invented by Google Researchers.\n\n\nRefer to large, general-purpose language models can be pre-trained and then fine-tuned for specific purpose\n\nLarge :\n\nLarge training dataset PetaBytes\nLarge number of parameters trillions\n\nLLM are trained to solve :\n\nText classification\nQuestion answering\nDocument summarization\nText generation\n\n\n\n\n\n\nCreate :\n\nGenerate description from images\nImprove images\n\nSummarize:\n\nVideos, audio and paragraphs\nGeneate Q&A\n\nDiscover\n\nSearch for a document\nDiscover coding bugs\n\nAutomate\n\nExtract and label contracts\nclassify feedback and create ticket\n\n\n\n\n\nCode assistance provides AI-driven code assistance for cloud users such as application developers and data engineers.\n\n\n\nModel Garden is a single place to discover and interact with many of Google’s pre-trained and open-source models\nCategories of models\n\nFoundation models\n\nPaLM for text\nPaLM for chat\nImagen for image\nEmbeddings API for text and image\nChirp for speech\nCodey for code generation\n\nTask-specific solutions\n\nEntity analysis\nSentiment analysis\nSyntax analysis\nContent classification\nObject detector\nText translation\n\nFine-tunable or open-source models\n\n\n\n\nWe can use Generative AI Studio to quickly prototype and customize generative AI models with no or low code.\nThat support Language, Vision and Speech"
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-2-collaborating-within-and-across-teams-to-manage-data-and-models-16-of-the-exam",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-2-collaborating-within-and-across-teams-to-manage-data-and-models-16-of-the-exam",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Cloud Spanner, Cloud SQL, Apache Spark, Apache Hadoop).\n2.2 Model prototyping using Jupyter notebooks.\n2.3 Tracking and running ML experiments."
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-3-scaling-prototypes-into-ml-models-18-of-the-exam",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-3-scaling-prototypes-into-ml-models-18-of-the-exam",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "3.1 Building models.\n3.2 Training models.\n3.3 Choosing appropriate hardware for training."
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-4-serving-and-scaling-models-19-of-the-exam",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-4-serving-and-scaling-models-19-of-the-exam",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "4.1 Serving models.\n4.2 Scaling online model serving."
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-5-automating-and-orchestrating-ml-pipelines-21-of-the-exam",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-5-automating-and-orchestrating-ml-pipelines-21-of-the-exam",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "5.1 Developing end-to-end ML pipelines.\n5.2 Automating model retraining.\n5.3 Tracking and auditing metadata."
  },
  {
    "objectID": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-6-monitoring-ml-solutions-14-of-the-exam",
    "href": "notas/2023-09-06-GCP-ML-Engineer/index.html#section-6-monitoring-ml-solutions-14-of-the-exam",
    "title": "Professional Machine Learning Engineer",
    "section": "",
    "text": "6.1 Identifying risks to ML solutions.\n6.2 Monitoring, testing, and troubleshooting ML solutions."
  },
  {
    "objectID": "notas/2023-09-01-deep-learning/index.html#noteook-prof-jeremy-howard",
    "href": "notas/2023-09-01-deep-learning/index.html#noteook-prof-jeremy-howard",
    "title": "Deep learning for Coders fast.ai",
    "section": "Noteook Prof JEREMY HOWARD",
    "text": "Noteook Prof JEREMY HOWARD\nhttps://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners"
  }
]